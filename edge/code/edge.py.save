import os
import time
import threading
import random
import requests
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from flask import Flask, request, jsonify
from model import MLPClassifier

# ------------------ Configuration ------------------ #
SERVER_URL = "https://9953-87-255-216-86.ngrok-free.app"  # Federated server endpoint
DEVICE_ID = 1
LOCAL_DATA_PATH = f"./local_storage/local_data_{DEVICE_ID}.csv"
RETRAIN_THRESHOLD = 10
COOLDOWN_PERIOD = 30
NORMAL_FEEDBACK_PROB = 0.7
TRAINING_CHECK_INTERVAL = 10  # Seconds between checks for retraining

# Ensure local storage exists
os.makedirs("./local_storage", exist_ok=True)
if not os.path.exists(LOCAL_DATA_PATH):
    pd.DataFrame(columns=["HR", "BT", "SpO2", "Age", "Gender", "Outcome"]).to_csv(LOCAL_DATA_PATH, index=False)

# ------------------ Flask App ------------------ #
app = Flask(__name__)

# ------------------ Model Initialization ------------------ #
model = MLPClassifier()
model_path = "./local_storage/edge_model.pth"

if os.path.exists(model_path):
    model.load_state_dict(torch.load(model_path))
    print("Model loaded successfully from local storage.")
else:
    print("No saved local model found, using initial model.")

model.eval()  # Start in eval mode


# ------------------ Utility Functions ------------------ #
def state_dict_to_json(state_dict):
    """Convert a PyTorch state_dict to JSON-serializable format."""
    return {k: v.cpu().numpy().tolist() for k, v in state_dict.items()}

def json_to_state_dict(json_dict):
    """Convert a JSON-serialized state_dict back to PyTorch format."""
    return {k: torch.tensor(v) for k, v in json_dict.items()}

def download_global_model():
    """Download the global model from the federated server."""
    try:
        response = requests.get(f"{SERVER_URL}/model")
        if response.status_code == 200:
            json_state = response.json()
            return json_to_state_dict(json_state)
        else:
            print("Error downloading global model:", response.text)
    except Exception as e:
        print(f"Exception during model download: {e}")
    return None

def fetch_global_model():
    """Fetch and update local model with the latest global model."""
    global_state = download_global_model()
    if global_state:
        model.load_state_dict(global_state, strict=False)
        print("Global model updated locally.")
    else:
        print("Failed to fetch global model; using local copy.")

def train_local_model(local_model, X, y, epochs=3, batch_size=16, learning_rate=0.01):
    """Retrain the local model on new data."""
    local_model.train()
    dataset = TensorDataset(torch.from_numpy(X), torch.from_numpy(y))
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(local_model.parameters(), lr=learning_rate)

    for epoch in range(epochs):
        epoch_loss = 0.0
        for batch_X, batch_y in loader:
            optimizer.zero_grad()
            outputs = local_model(batch_X)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item() * batch_X.size(0)
        epoch_loss /= len(dataset)
        print(f"[Local Training] Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}")

    local_model.eval()
    return local_model

def send_model_update(local_model):
    """Send updated local model params to the federated server."""
    try:
        current_state = state_dict_to_json(local_model.state_dict())
        response = requests.post(f"{SERVER_URL}/update", json=current_state)
        print("Server response:", response.json())
    except Exception as e:
        print(f"Error sending update: {e}")

def save_new_data(sensor_sample):
    """Append a sensor sample to the local CSV dataset."""
    try:
        df = pd.DataFrame([sensor_sample])
        df.to_csv(LOCAL_DATA_PATH, mode="a", header=False, index=False)
        print("Sample saved to local storage.")
    except Exception as e:
        print(f"Error saving new data: {e}")


# ------------------ Federated Edge Logic ------------------ #
def federated_training_loop():
    """Periodically checks if enough data is available to retrain and update server."""
    last_update_time = 0
    while True:
        time.sleep(TRAINING_CHECK_INTERVAL)  # Wait before checking

        # Load local data
        try:
            df_local = pd.read_csv(LOCAL_DATA_PATH)
        except:
            df_local = pd.DataFrame(columns=["HR", "BT", "SpO2", "Age", "Gender", "Outcome"])

        if len(df_local) >= RETRAIN_THRESHOLD:
            # Retrain local model
            print("Retraining local model - data threshold reached.")
            X = df_local[["HR", "BT", "SpO2", "Age", "Gender"]].values.astype(np.float32)
            y = df_local["Outcome"].values.astype(np.int64)
            train_local_model(model, X, y, epochs=3)

            # Attempt to send model update if cooldown has passed
            current_time = time.time()
            if (current_time - last_update_time) > COOLDOWN_PERIOD:
                send_model_update(model)
                last_update_time = current_time
            else:
                print("Skipping update due to cooldown.")

        # Optionally, you can refetch the global model if you want to stay updated:
        # fetch_global_model()


# ------------------ Flask Routes for Sensor Data ------------------ #
@app.route('/send_data', methods=['POST'])
def sensor_data():
    """
    Receives sensor data in JSON:
    {
        "HR": float,
        "BT": float,
        "SpO2": float,
        "Age": float,
        "Gender": float,
        "Outcome": optional
    }
    - Predict anomaly
    - Possibly store sample with user feedback
    - Return JSON with anomaly result
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No data received"}), 400

        # Extract features
        features = [
            data.get("HR", 0),
            data.get("BT", 0),
            data.get("SpO2", 0),
            data.get("Age", 0),
            data.get("Gender", 0)
        ]
        x = torch.tensor(features, dtype=torch.float32).unsqueeze(0)

        # Predict
        model.eval()
        with torch.no_grad():
            output = model(x)
            prediction = torch.argmax(output, dim=1).item()  # 0 or 1

        # If there's an 'Outcome' in the JSON, treat it as user feedback
        user_outcome = data.get("Outcome", None)
        sample_dict = {
            "HR": features[0],
            "BT": features[1],
            "SpO2": features[2],
            "Age": features[3],
            "Gender": features[4],
            "Outcome": user_outcome if user_outcome is not None else prediction
        }
        # Save the sample for local retraining
        save_new_data(sample_dict)

        return jsonify({
            "status": "success",
            "anomaly": prediction
        }), 200
    except Exception as e:
        print(f"API Error: {e}")
        return jsonify({"error": "Internal server error"}), 500


# ------------------ Main Entry Point ------------------ #
if __name__ == "__main__":
    # Optionally fetch the global model at startup
    fetch_global_model()

    # Start the federated training loop in a separate thread
    threading.Thread(target=federated_training_loop, daemon=True).start()

    # Run the Flask server to receive sensor data
    print("Edge Device API starting on 0.0.0.0:5001...")
    app.run(host='0.0.0.0', port=5001, debug=False)
